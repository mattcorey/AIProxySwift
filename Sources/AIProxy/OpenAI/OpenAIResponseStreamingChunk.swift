//
//  OpenAIResponseStreamingChunk.swift
//  AIProxy
//
//  Created by Claude on 6/20/25.
//

import Foundation

/// Represents a streamed chunk of a response returned by model, based on the provided input.
/// https://platform.openai.com/docs/api-reference/responses/streaming
public struct OpenAIResponseStreamingChunk: Decodable {

    /// The Unix timestamp (in seconds) of when the response was created. Each chunk has the same timestamp.
    public let createdAt: Double?

    /// A unique identifier for the response. Each chunk has the same ID.
    public let id: String?

    /// The model to generate the response.
    public let model: String?

    /// The object type identifier for this response chunk.
    public let object: String?

    /// A list of response choices. Can contain more than one elements if multiple choices are requested.
    /// Can also be empty for the last chunk, which contains usage information only.
    public let choices: [Choice]

    /// This property is nil for all chunks except for the last chunk, which contains the token
    /// usage statistics for the entire request.
    public let usage: OpenAIResponse.ResponseUsage?
    
    public init(createdAt: Double?, id: String?, model: String?, object: String?, choices: [Choice], usage: OpenAIResponse.ResponseUsage?) {
        self.createdAt = createdAt
        self.id = id
        self.model = model
        self.object = object
        self.choices = choices
        self.usage = usage
    }

    private enum CodingKeys: String, CodingKey {
        case createdAt = "created_at"
        case id
        case model
        case object
        case choices
        case usage
    }
}

// MARK: -
extension OpenAIResponseStreamingChunk {
    /// https://platform.openai.com/docs/api-reference/responses/streaming#responses/streaming-choices
    public struct Choice: Decodable {
        /// A response delta generated by streamed model responses.
        public let delta: Delta

        /// The reason the model stopped generating tokens. This will be stop if the model hit a natural stop point,
        /// length if the maximum number of tokens specified in the request was reached, content_filter if content was 
        /// omitted due to a flag from content filters, or tool_calls if the model called a tool.
        public let finishReason: String?

        /// The index of the choice in the list of choices.
        public let index: Int?
        
        public init(delta: Delta, finishReason: String?, index: Int?) {
            self.delta = delta
            self.finishReason = finishReason
            self.index = index
        }

        private enum CodingKeys: String, CodingKey {
            case delta
            case finishReason = "finish_reason"
            case index
        }
    }
}

// MARK: -
extension OpenAIResponseStreamingChunk.Choice {
    /// A response delta generated by streamed model responses.
    public struct Delta: Decodable {

        /// The type of this delta item
        public let type: String?

        /// The delta content for message types
        public let content: [ContentDelta]?

        /// The delta for tool calls
        public let toolCalls: [ToolCallDelta]?
        
        public init(type: String?, content: [ContentDelta]?, toolCalls: [ToolCallDelta]?) {
            self.type = type
            self.content = content
            self.toolCalls = toolCalls
        }

        private enum CodingKeys: String, CodingKey {
            case type
            case content
            case toolCalls = "tool_calls"
        }
    }
}

// MARK: -
extension OpenAIResponseStreamingChunk.Choice.Delta {
    public struct ContentDelta: Decodable {
        /// The type of content delta
        public let type: String?
        
        /// The incremental text content
        public let text: String?
        
        public init(type: String?, text: String?) {
            self.type = type
            self.text = text
        }
    }
    
    public struct ToolCallDelta: Decodable {
        /// The index of this tool call in the list
        public let index: Int?
        
        /// The ID of the tool call
        public let id: String?
        
        /// The type of the tool (e.g., "function")
        public let type: String?
        
        /// The function call delta if this is a function tool
        public let function: FunctionDelta?
        
        public init(index: Int?, id: String?, type: String?, function: FunctionDelta?) {
            self.index = index
            self.id = id
            self.type = type
            self.function = function
        }
    }
    
    public struct FunctionDelta: Decodable {
        /// The name of the function being called
        public let name: String?
        
        /// The incremental arguments for the function call
        public let arguments: String?
        
        public init(name: String?, arguments: String?) {
            self.name = name
            self.arguments = arguments
        }
    }
}